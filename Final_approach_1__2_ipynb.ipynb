{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arminmu13106-art/TEAM7-Capstone-Project/blob/main/Final_approach_1__2_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gen AI:\n",
        "\n",
        "Since I can't import files into Colab, I asked AI if there are other methods: I can't import files into Colab. Please tell me if there are other methods.\n",
        "\n",
        "See Data Tell me what positions and grades are listed in the document.\n",
        "\n",
        "Improve optimization rate Please optimize the keywords for me to improve the prediction accuracy.\n",
        "\n",
        "Model Search Provide me with models that may be suitable."
      ],
      "metadata": {
        "id": "miBsWNJ-9UmU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0G1tSwQVvyb"
      },
      "outputs": [],
      "source": [
        "  # Rule-based matching (baseline): Identify relevant job titles and text passages using predefined label lists and assign domain and seniority accordingly.\n",
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Load Data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/linkedin-cvs-annotated.json'\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as f:\n",
        "    raw_data = json.load(f)\n",
        "\n",
        "# 2. Flattening\n",
        "# Create an empty list\n",
        "flattened_records = []\n",
        "#Open each resume one by one\n",
        "for person_cv in raw_data:\n",
        "    for job in person_cv:\n",
        "        if job.get('status') == 'ACTIVE':\n",
        "            flattened_records.append(job)\n",
        "# Change the format\n",
        "df = pd.DataFrame(flattened_records)\n",
        "\n",
        "# 3. Define Rules\n",
        "dept_rules = {\n",
        "    'Information Technology': ['it', 'information technology', 'software', 'developer', 'engineer', 'systems', 'system administrator', 'network', 'architect','cloud', 'devops', 'data', 'infrastructure'],\n",
        "\n",
        "    'Customer Support': ['customer support', 'support specialist', 'technical support', 'service desk', 'helpdesk', 'customer service', 'support engineer', 'maintenance', 'after sales'],\n",
        "\n",
        "    'Consulting': ['consultant', 'consulting', 'advisory','management consulting', 'strategy consulting', 'technology consulting', 'medical consulting'],\n",
        "\n",
        "    'Project Management': ['project manager', 'project management', 'program manager', 'quality management', 'delivery manager','project lead', 'development lead'],\n",
        "\n",
        "    'Sales': ['sales', 'account manager', 'key account', 'sales manager', 'business sales', 'commercial', 'sales director'],\n",
        "\n",
        "    'Business Development': ['business development', 'bd manager', 'growth', 'strategic partnership', 'partnerships', 'alliances'],\n",
        "\n",
        "    'Administrative': ['administrative', 'administration', 'operations coordinator', 'office manager', 'business planning', 'system coordination'],\n",
        "\n",
        "    'Marketing': ['marketing', 'digital marketing', 'online marketing', 'brand', 'content', 'seo', 'sem','graphic designer', 'art director', 'communications'],\n",
        "\n",
        "    'Human Resources': ['human resources', 'hr', 'people', 'talent', 'recruitment', 'recruiter', 'hr manager', 'people operations'],\n",
        "\n",
        "    'Purchasing': ['purchasing', 'procurement', 'buyer', 'sourcing', 'supply', 'demand manager', 'global demand', 'project accounting']\n",
        "}\n",
        "\n",
        "seniority_rules = {\n",
        "    'Director': ['director', 'vice president', 'vp', 'board', 'partner'],\n",
        "    'Management': ['manager', 'head', 'chief', 'executive', 'managing', 'supervisor', 'leiter'],\n",
        "    'Lead': ['lead', 'team lead', 'tech lead', 'project lead'],\n",
        "    'Senior': ['senior', 'sr', 'expert', 'principal', 'staff'],\n",
        "    'Junior': ['junior', 'assistant', 'entry', 'intern', 'trainee', 'working student', 'student','apprentice']\n",
        "}\n",
        "\n",
        "# 4. Prediction Function\n",
        "def rule_based_match(text, rules_dict, default_val):\n",
        "    if pd.isna(text):\n",
        "        return default_val\n",
        "    # Standardized lowercasing\n",
        "    text = str(text).lower()\n",
        "    for label, keywords in rules_dict.items():\n",
        "        for kw in keywords:\n",
        "            if kw in text:\n",
        "                return label\n",
        "    return default_val\n",
        "\n",
        "# 5. Apply Predictions\n",
        "df['pred_dept'] = df['position'].apply(rule_based_match, args=(dept_rules, 'Other'))\n",
        "df['pred_sen'] = df['position'].apply(rule_based_match, args=(seniority_rules, 'Professional'))\n",
        "\n",
        "# 6. Results & Evaluation\n",
        "print(f\"Domain Prediction Accuracy: {accuracy_score(df['department'], df['pred_dept']):.2%}\")\n",
        "print(f\"Seniority Prediction Accuracy: {accuracy_score(df['seniority'], df['pred_sen']):.2%}\")\n",
        "\n",
        "# 7. Result Showcase\n",
        "print(\"\\nPrediction Examples:\")\n",
        "print(df[['position', 'department', 'pred_dept', 'seniority', 'pred_sen']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCCvizGuCY9V"
      },
      "outputs": [],
      "source": [
        "#Embedding-based labeling: Use the provided label lists to generate embeddings (e.g., via LLMs or sentence transformers). Compute similarity between profile text and label embeddings and perform zero-shot classification.\n",
        "import pandas as pd\n",
        "import json\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df_dept = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/department-v2.csv')\n",
        "df_sen  = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/seniority-v2.csv')\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/linkedin-cvs-annotated.json'\n",
        "with open(file_path, 'r', encoding='utf-8') as f:\n",
        "    raw_data = json.load(f)\n",
        "\n",
        "records = []\n",
        "for person_cv in raw_data:\n",
        "    for job in person_cv:\n",
        "        if job.get('status') == 'ACTIVE':\n",
        "            records.append(job)\n",
        "\n",
        "df_test = pd.DataFrame(records)\n",
        "\n",
        "# Label Lists\n",
        "dept_labels = sorted(df_dept['label'].unique().tolist())\n",
        "sen_labels  = sorted(df_sen['label'].unique().tolist())\n",
        "\n",
        "test_positions = df_test['position'].astype(str).tolist()\n",
        "\n",
        "# Zero-shot\n",
        "def predict_labels(text_embeds, label_embeds, label_list):\n",
        "    sim_matrix = util.cos_sim(text_embeds, label_embeds)\n",
        "    best_indices = torch.argmax(sim_matrix, dim=1).cpu().tolist()\n",
        "    return [label_list[i] for i in best_indices]\n",
        "\n",
        "# Modell List\n",
        "basic_transformer_models = [\n",
        "                     \"all-mpnet-base-v2\",\n",
        "                     \"all-MiniLM-L6-v2\",\n",
        "                     \"multi-qa-mpnet-base-dot-v1\",\n",
        "                     \"paraphrase-multilingual-mpnet-base-v2\",\n",
        "                     \"distiluse-base-multilingual-cased-v2\",\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for model_name in basic_transformer_models:\n",
        "    print(f\"\\Testing model: {model_name}\")\n",
        "\n",
        "    try:\n",
        "        model = SentenceTransformer(model_name)\n",
        "\n",
        "        # label embeddings\n",
        "        dept_label_embeddings = model.encode(\n",
        "            dept_labels, convert_to_tensor=True, normalize_embeddings=True\n",
        "        )\n",
        "        sen_label_embeddings = model.encode(\n",
        "            sen_labels, convert_to_tensor=True, normalize_embeddings=True\n",
        "        )\n",
        "\n",
        "        # position embeddings\n",
        "        position_embeddings = model.encode(\n",
        "            test_positions,\n",
        "            convert_to_tensor=True,\n",
        "            show_progress_bar=True,\n",
        "            normalize_embeddings=True\n",
        "        )\n",
        "\n",
        "        # predictions\n",
        "        df_test['pred_department'] = predict_labels(\n",
        "            position_embeddings, dept_label_embeddings, dept_labels\n",
        "        )\n",
        "        df_test['pred_seniority'] = predict_labels(\n",
        "            position_embeddings, sen_label_embeddings, sen_labels\n",
        "        )\n",
        "\n",
        "        # evaluation\n",
        "        dept_acc = accuracy_score(df_test['department'], df_test['pred_department'])\n",
        "        sen_acc  = accuracy_score(df_test['seniority'], df_test['pred_seniority'])\n",
        "\n",
        "        results.append({\n",
        "            \"model\": model_name,\n",
        "            \"department_acc\": dept_acc,\n",
        "            \"seniority_acc\": sen_acc,\n",
        "        })\n",
        "\n",
        "        print(f\"Department Acc: {dept_acc:.2%}\")\n",
        "        print(f\"Seniority Acc: {sen_acc:.2%}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Model {model_name} failed: {e}\")\n",
        "\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "best_dept_idx = results_df['department_acc'].idxmax()\n",
        "best_sen_idx  = results_df['seniority_acc'].idxmax()\n",
        "\n",
        "best_dept_model = results_df.loc[best_dept_idx]\n",
        "best_sen_model = results_df.loc[best_sen_idx]\n",
        "\n",
        "\n",
        "print(f\"Best Model for Department Classification:\")\n",
        "print(f\"Model Name: {best_dept_model['model']}\")\n",
        "print(f\"Accuracy: {best_dept_model['department_acc']:.2%}\")\n",
        "\n",
        "print(f\"Best Model for Seniority Classification:\")\n",
        "print(f\"Model Name: {best_sen_model['model']}\")\n",
        "print(f\"Accuracy: {best_sen_model['seniority_acc']:.2%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be observed that the prediction success rate of Embedding-based labeling is lower than that of Rule-based matching (baseline). Even after attempting various models, its highest prediction accuracy remains below 35%. However, when the training set is split into 80% for training and 20% for testing, the success rate reaches about 80%. This suggests an occurrence of overfitting. Additionally, the emergence of new classifications in the test set is also a likely factor contributing to the prediction rate falling below 35%."
      ],
      "metadata": {
        "id": "DiPzySgKv62N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extensions: The seniority level typically increases over time"
      ],
      "metadata": {
        "id": "Y1pktrgoWezM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJ3IL9RTWqGF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df_dept = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/department-v2.csv')\n",
        "df_sen  = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/seniority-v2.csv')\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/linkedin-cvs-annotated.json'\n",
        "with open(file_path, 'r', encoding='utf-8') as f:\n",
        "    raw_data = json.load(f)\n",
        "\n",
        "# Label Lists\n",
        "dept_labels = sorted(df_dept['label'].unique().tolist())\n",
        "\n",
        "# seniority Order\n",
        "sen_labels = [\"Junior\", \"Senior\", \"Lead\", \"Management\", \"Director\"]\n",
        "\n",
        "sen_order = {l: i for i, l in enumerate(sen_labels)}\n",
        "inv_sen_order = {i: l for l, i in sen_order.items()}\n",
        "\n",
        "\n",
        "# Zero-shot\n",
        "def predict_labels(text_embeds, label_embeds, label_list):\n",
        "    sim_matrix = util.cos_sim(text_embeds, label_embeds)\n",
        "    best_indices = torch.argmax(sim_matrix, dim=1).cpu().tolist()\n",
        "    return [label_list[i] for i in best_indices]\n",
        "\n",
        "# Modell List\n",
        "basic_transformer_models = [\n",
        "                     \"all-mpnet-base-v2\",\n",
        "                     \"all-MiniLM-L6-v2\",\n",
        "                     \"multi-qa-mpnet-base-dot-v1\",\n",
        "                     \"paraphrase-multilingual-mpnet-base-v2\",\n",
        "                     \"distiluse-base-multilingual-cased-v2\",\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for model_name in basic_transformer_models:\n",
        "    print(f\"\\nTesting model: {model_name}\")\n",
        "\n",
        "    try:\n",
        "        model = SentenceTransformer(model_name)\n",
        "\n",
        "        # label embeddings\n",
        "        dept_label_embeddings = model.encode(\n",
        "            dept_labels, convert_to_tensor=True, normalize_embeddings=True\n",
        "        )\n",
        "        sen_label_embeddings = model.encode(\n",
        "            sen_labels, convert_to_tensor=True, normalize_embeddings=True\n",
        "        )\n",
        "\n",
        "        y_true_dept = []\n",
        "        y_pred_dept = []\n",
        "        y_true_sen = []\n",
        "        y_pred_sen = []\n",
        "\n",
        "        for person_cv in raw_data:\n",
        "            # time based order\n",
        "            jobs = sorted(person_cv,key=lambda x: x.get(\"start_date\", \"\"))\n",
        "\n",
        "            texts = [str(j.get(\"position\", \"\")) for j in jobs]\n",
        "\n",
        "            embeds = model.encode(\n",
        "                texts,\n",
        "                convert_to_tensor=True,\n",
        "                normalize_embeddings=True\n",
        "            )\n",
        "\n",
        "            curr_dept_preds = predict_labels(embeds, dept_label_embeddings, dept_labels)\n",
        "            curr_sen_preds = predict_labels(embeds, sen_label_embeddings, sen_labels)\n",
        "\n",
        "            numeric_sen_preds = [sen_order[p] for p in curr_sen_preds]\n",
        "\n",
        "            active_idx = None\n",
        "            for i, j in enumerate(jobs):\n",
        "                if j.get(\"status\") == \"ACTIVE\":\n",
        "                    active_idx = i\n",
        "                    break\n",
        "\n",
        "            if active_idx is None:\n",
        "                continue\n",
        "\n",
        "            if active_idx:\n",
        "                constrained_val = max(numeric_sen_preds[:active_idx + 1])\n",
        "                final_sen_pred = inv_sen_order[constrained_val]\n",
        "\n",
        "            else:\n",
        "                final_sen_pred = curr_sen_preds[active_idx]\n",
        "\n",
        "            # 5. data collection\n",
        "            true_dept = jobs[active_idx].get(\"department\")\n",
        "            true_sen  = jobs[active_idx].get(\"seniority\")\n",
        "\n",
        "            # skip if missing annotations\n",
        "            if true_dept is None or true_sen is None:\n",
        "              continue\n",
        "\n",
        "            y_true_dept.append(str(true_dept).strip())\n",
        "            y_pred_dept.append(str(curr_dept_preds[active_idx]).strip())\n",
        "\n",
        "            y_true_sen.append(str(true_sen).lower().strip())\n",
        "            y_pred_sen.append(str(final_sen_pred).lower().strip())\n",
        "\n",
        "        # Accuracy\n",
        "        dept_acc = accuracy_score(y_true_dept, y_pred_dept)\n",
        "        sen_acc_2 = accuracy_score(y_true_sen, y_pred_sen)\n",
        "\n",
        "        results.append({\n",
        "            \"model\": model_name,\n",
        "            \"department_acc\": dept_acc,\n",
        "            \"seniority_acc_2\": sen_acc_2,\n",
        "        })\n",
        "\n",
        "        print(f\"Department Acc: {dept_acc:.2%}\")\n",
        "        print(f\"Seniority Acc 2: {sen_acc_2:.2%}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Model {model_name} failed: {e}\")\n",
        "\n",
        "# evaluation\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "best_dept_idx = results_df['department_acc'].idxmax()\n",
        "best_sen_idx  = results_df['seniority_acc_2'].idxmax()\n",
        "\n",
        "best_dept_model = results_df.loc[best_dept_idx]\n",
        "best_sen_model = results_df.loc[best_sen_idx]\n",
        "\n",
        "print(f\"Best Model for Department Classification:\")\n",
        "print(f\"Model Name: {best_dept_model['model']}\")\n",
        "print(f\"Accuracy: {best_dept_model['department_acc']:.2%}\")\n",
        "\n",
        "print(f\"Best Model for Seniority Classification (Method 2):\")\n",
        "print(f\"Model Name: {best_sen_model['model']}\")\n",
        "print(f\"Accuracy: {best_sen_model['seniority_acc_2']:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above methods assume that job seniority levels generally do not decrease. We observe that accuracy improvements do not exceed 1%, and the optimal models remain unchanged. Therefore, paraphrase-multilingual-mpnet-base-v2 and multi-qa-mpnet-base-dot-v1 are identified as the optimal models for predicting Department and Seniority, respectively. When utilizing these models, the assumption that job seniority levels typically do not decrease can be disregarded."
      ],
      "metadata": {
        "id": "_ShNs8diECo-"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1bNtASnTgUdgbs2gfUg9isa4TknayQ6dy",
      "authorship_tag": "ABX9TyONWXG1KfeV3sIIp3pbblTk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}